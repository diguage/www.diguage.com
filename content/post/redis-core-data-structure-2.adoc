---
title: "Redis 核心数据结构（二）"
date: 2020-07-02T11:11:11+08:00
draft: false
keywords: ["Redis","Spring"]
tags: ["存储","设计","架构"]
categories: ["程序设计","算法","分布式"]

weight: 1

# You can also close(false) or open(true) something for this content.
# P.S. comment can only be closed
# comment: false
# toc: true
---

:source-highlighter: pygments
:pygments-style: monokai
:pygments-linenums-mode: table
:source_attr: indent=0,subs="attributes,verbatim"


在上一篇文章： https://www.diguage.com/post/redis-core-data-structure-1/[Redis 核心数据结构（1）] 中，介绍了链表、ziplist、quicklist 数据结构。这篇文章，来介绍一下 skiplist、dict。

== skiplist

跳跃表是一种有序数据结构，支持平均 O(logN)、最坏 O(N) 复杂度的节点查找；大部分情况效率可以和平衡树相媲美，实现却比平衡树简单。

跳跃表就是 Redis 中有序集合键的底层实现之一。

// ****
// 还有其他什么实现？
// ****

.server.h
[source,c,{source_attr}]
----
typedef struct zskiplistNode {
    sds ele;
    double score;
    struct zskiplistNode *backward;
    struct zskiplistLevel {
        struct zskiplistNode *forward;
        unsigned long span;
    } level[];
} zskiplistNode;

typedef struct zskiplist {
    struct zskiplistNode *header, *tail;
    unsigned long length;
    int level;
} zskiplist;

typedef struct zset {
    dict *dict;
    zskiplist *zsl;
} zset;
----

skiplist，顾名思义，首先它是一个list。实际上，它是在有序链表的基础上发展起来的。

image::/images/redis/skiplist.png[]

当我们想查找数据的时候，可以先沿着跨度大的链进行查找。当碰到比待查数据大的节点时，再回到跨度小的链表中进行查找。

skiplist正是受这种多层链表的想法的启发而设计出来的。按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到 O(logN)。但是，存在的一个问题是：如果插入新节点后就会打乱上下相邻两层节点是 2:1 的对应关系。如果要维持，则需要调整后面所有的节点。

skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。

image::/images/redis/redis-skiplist-insertions.png[]

插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上，这是 skiplist 的一个很重要的特性，这让它在插入性能上明显优于平衡树的方案。

skiplist，翻译成中文，可以翻译成“跳表”或“跳跃表”，指的就是除了最下面第1层链表之外，它会产生若干层稀疏的链表，这些链表里面的指针故意跳过了一些节点（而且越高层的链表跳过的节点越多）。这就使得我们在查找数据的时候能够先在高层的链表中进行查找，然后逐层降低，最终降到第1层链表来精确地确定数据位置。在这个过程中，我们跳过了一些节点，从而也就加快了查找速度。

****
. 在中间插入一个有比较高 Level 的节点，如何维护前面节点到这个节点的这些链接？
. 在平衡树种，如何做范围查找？先确定边界，然后其他节点怎么查找？
****

image::/images/redis/redis_skiplist_example.png[]

. skiplist 中 key 允许重复。
. 在比较时，不仅比较分数（即key），还要比较数据自身。
. 第一层链表是双向链表，并且反向指针只有一个。
. 在 skiplist 中可以很方便计算每个元素的排名。

Redis 中的有序集合（sorted set），是在 skiplist, dict 和 ziplist 基础上构建起来的:

. 当数据较少时，sorted set是由一个 ziplist 来实现的。其中集合元素按照分值从小到大排序。
. 当数据多的时候，sorted set 是由一个叫 zset 的数据结构来实现的，这个 zset 包含一个 dict + 一个 skiplist。dict 用来查询数据到分数(score)的对应关系，而 skiplist 用来根据分数查询数据（可能是范围查找）。

转换的条件是：

. 有序集合保存的元素数量小于 128 个；（通过参数 `zset-max-ziplist-entries` 来调节，默认为 128。）
. 有序集合保存的所有元素成员的长度都要小于 64 个字节；（通过参数 `zset-max-ziplist-value` 来调节，默认为 64。）

在 `t_zset.c/zsetConvert` 中执行转换操作。

[source,bash,{source_attr}]
----
$ redis-cli --raw

127.0.0.1:6379> ZADD NameRanking 1 "D瓜哥"
1

127.0.0.1:6379> ZADD NameRanking 2 "https://www.diguage.com"
1

127.0.0.1:6379> ZADD NameRanking 3 "https://github.com/diguage"
1

127.0.0.1:6379> ZRANGE NameRanking 0 -1 WITHSCORES
D瓜哥
1
https://www.diguage.com
2
https://github.com/diguage
3

127.0.0.1:6379> TYPE NameRanking
zset

127.0.0.1:6379> OBJECT encoding NameRanking
ziplist

127.0.0.1:6379> ZADD NameRanking 4 "1234567890123456789012345678901234567890123456789012345678901234"
1

127.0.0.1:6379> ZRANGE NameRanking 0 -1 WITHSCORES
D瓜哥
1
https://www.diguage.com
2
https://github.com/diguage
3
1234567890123456789012345678901234567890123456789012345678901234
4

127.0.0.1:6379> OBJECT encoding NameRanking
ziplist

127.0.0.1:6379> ZADD NameRanking 5 "12345678901234567890123456789012345678901234567890123456789012345"
1

127.0.0.1:6379> ZRANGE NameRanking 0 -1 WITHSCORES
D瓜哥
1
https://www.diguage.com
2
https://github.com/diguage
3
1234567890123456789012345678901234567890123456789012345678901234
4
12345678901234567890123456789012345678901234567890123456789012345
5

127.0.0.1:6379> OBJECT encoding NameRanking
skiplist

127.0.0.1:6379> TYPE NameRanking
zset
----

在 JDK 中，也有 skiplist 的实现，在 `ConcurrentSkipListMap` 中。不过，它不是作为一个独立的 `Collection` 来实现的，而是作为 `Map` 的一部分来实现的。

== dict

Redis 底层中的字典就是一个典型的 Hash 实现。

.dict.h
[source,c,{source_attr}]
----
typedef struct dictEntry { // <1>
    void *key;
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;
} dictEntry;

typedef struct dictType {
    uint64_t (*hashFunction)(const void *key);
    void *(*keyDup)(void *privdata, const void *key);
    void *(*valDup)(void *privdata, const void *obj);
    int (*keyCompare)(void *privdata, const void *key1, const void *key2);
    void (*keyDestructor)(void *privdata, void *key);
    void (*valDestructor)(void *privdata, void *obj);
} dictType;

/* This is our hash table structure. Every dictionary has two of this as we
 * implement incremental rehashing, for the old to the new table. */
typedef struct dictht {
    dictEntry **table; // <2>
    unsigned long size;
    unsigned long sizemask;
    unsigned long used;
} dictht;

typedef struct dict {
    dictType *type;
    void *privdata;
    dictht ht[2]; // <3>
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */
    unsigned long iterators; /* number of iterators currently running */
} dict;
----
<1> `dictEntry` 保存一个键值对。
<2> `table` 属性是一个数组，数组中每个元素都是一个指向 `dictEntry` 结构的指针。
<3> 通常使用 `ht[0]`，`ht[1]` 在 Rehash 时才会用到。

添加新元素时，和 Java 一样，计算 Key 的哈希值，然后再根据哈希值与长度掩码（`sizemask`）相与得到数组下标。

Redis 底层使用 https://en.wikipedia.org/wiki/MurmurHash[MurmurHash2^] 算法来计算键的哈希值。

// TODO 几种常见的 Hash 算法可以研究一下。

=== Rehash 操作

. 计算新的数组长度
.. 如果是扩容，则 `used * 2`；
.. 如果是缩容，则是第一个大于等于 `used` 的 2^n^。 -- 这点和 Java 不同，`HashMap` 中没有自动缩容的机制。
. 将 `ht[0]` 中的所有键值对重新 Rehash，重新计算哈希值和索引值，放置到 `ht[1]` 上；
. 迁移完成后，将 `ht[1]` 设置为 `ht[0]`，为 `ht[1]` 创建一个空白哈希表。

还有几点需要特别注意：

. 根据是否正在执行 `BGSAVE` 或 `BGREADWRITEAOF` 命令，使用不同的负载阈值来决定是否开启对哈希表的自动扩展工作；
. 当哈希表负载因子小于 0.1 时，会自动开始对哈希表缩容；
. Rehash 过程是渐进式的：
.. 开始 Rehash 后，每次对自动进行的添加、删除、查找或更新时，程序会自动将对应的键值对从 `ht[0]` Rehash 到 `ht[1]` 上；rehashidx 属性值增一。
.. 记得有后台定时任务来自动扩展的，怎么没有看到说明文档？

Redis 在哈希对象上的编码有可能是：

. ziplist
. hashtable

转换条件是：

. 哈希对象保存的所有键值对象字符串长度都小于 64 个字节；（通过参数 `hash-max-ziplist-value` 来调节，默认为 64）
. 哈希对象保存的键值对数量小于 512 个；（通过参数 `hash-max-ziplist-entries` 来调节，默认为 512）

[source,bash,{source_attr}]
----
$ redis-cli --raw

127.0.0.1:6379> HMSET profile name "D瓜哥" site "https://www.diguage.com" job "Developer"
OK

127.0.0.1:6379> TYPE profile
hash

127.0.0.1:6379> OBJECT encoding profile
ziplist

127.0.0.1:6379> HSET profile address "1234567890123456789012345678901234567890123456789012345678901234" // <1>
1

127.0.0.1:6379> HVALS profile
D瓜哥
https://www.diguage.com
Developer
1234567890123456789012345678901234567890123456789012345678901234
127.0.0.1:6379> OBJECT encoding profile
ziplist

127.0.0.1:6379> HSET profile address "12345678901234567890123456789012345678901234567890123456789012345" // <2>
0

127.0.0.1:6379> HVALS profile
https://www.diguage.com
D瓜哥
12345678901234567890123456789012345678901234567890123456789012345
Developer

127.0.0.1:6379> OBJECT encoding profile
hashtable
----
<1> 这是 64 个字符。
<2> 这是 65 个字符


通过 `t_hash.c/hashTypeConvertZiplist` 方法来转换。


== 参考资料

. ftp://ftp.cs.umd.edu/pub/skipLists/skiplists.pdf[William Pugh《Skip Lists: A Probabilistic Alternative to Balanced Trees》^]
. https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261425&idx=1&sn=d840079ea35875a8c8e02d9b3e44cf95&scene=21#wechat_redirect[Redis为什么用跳表而不用平衡树？- 张铁蕾^]
. https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261203&idx=1&sn=f7ff61ce42e29b874a8026683875bbb1&scene=21#wechat_redirect[Redis内部数据结构详解(1)——dict^]
. https://diguage.github.io/jdk-source-analysis/[JDK 源码分析^]

