---
title: "Kafka 学习笔记"
date: 2020-03-05T15:38:49+08:00
draft: true
keywords: ["Kafka"]
tags: ["分布式","消息队列","架构","笔记","网络"]
categories: ["分布式"]

weight: 1
// toc: true

# You can also close(false) or open(true) something for this content.
# P.S. comment can only be closed
# comment: false
# toc: true

---

Apache Kafka 是由 Apache 软件基金会开发的一个开源分布式消息队列，由 Scala 写成。Kafka 于 2010 年左右在 LinkedIn 上由包括 Jay Kreps，Jun Rao 和 Neha Narkhede 的团队开发。他们最初要解决的问题是低延迟地从 LinkedIn 网站和基础架构中提取大量事件数据，并将其吸收到利用 Hadoop 和实时事件处理系统的 lambda 架构中。并于 2011 年初开源。2012 年 10 月从 Apache Incubator 毕业。由于其出色的性能，迅速被广泛应用，并且从消息传递队列演变为功能完善的事件流平台。

Kafka 具有高性能、持久化、多副本备份、横向扩展能力。生产者往队列里写消息，消费者从队列里取消息进行业务逻辑。一般在架构设计中起到解耦、削峰、异步处理的作用。

image::/images/kafka-notes/kafka-mindmap.webp[]

== 为什么需要消息队列？

=== 削峰

数据库的处理能力是有限的，在峰值期，过多的请求落到后台，一旦超过系统的处理能力，可能会使系统挂掉。

image::/images/kafka-notes/mq-peak-clipping.png[]

如上图所示，系统的处理能力是 2k/s，MQ 处理能力是 8k/s，峰值请求 5k/s，MQ 的处理能力远远大于数据库，在高峰期，请求可以先积压在 MQ 中，系统可以根据自身的处理能力以 2k/s 的速度消费这些请求。

注意，上面的请求指的是写请求，查询请求一般通过缓存解决。

=== 解耦

如下场景，S 系统与 A、B、C 系统紧密耦合。由于需求变动，A 系统修改了相关代码，S 系统也需要调整 A 相关的代码。

过几天，C 系统需要删除，S 紧跟着删除 C 相关代码；又过了几天，需要新增 D 系统，S 系统又要添加与 D 相关的代码；再过几天，程序猿疯了...

image::/images/kafka-notes/coupling.png[]

这样各个系统紧密耦合，不利于维护，也不利于扩展。现在引入 MQ，A 系统变动，A 自己修改自己的代码即可；C 系统删除，直接取消订阅；D 系统新增，订阅相关消息即可。

image::/images/kafka-notes/mq-decoupling.webp[]

这样通过引入消息中间件，使各个系统都与 MQ 交互，从而避免它们之间的错综复杂的调用关系。

=== 异构系统整合

在计算机早起发展阶段，有各种各样的机器、系统以及伴随而来的各种协议。消息队列可以在中间起到一个协调整合的作用。

== Kafka 入门

Kafka 对外使用 topic 的概念，生产者往 topic 里写消息，消费者从读消息。为了做到水平扩展，一个 topic 实际是由多个 partition 组成的，遇到瓶颈时，可以通过增加 partition 的数量来进行横向扩容。单个 parition 内是保证消息有序。

每新写一条消息，Kafka 就是在对应的文件 append 写，所以性能非常高。

=== 科普时间

. 历史背景
. Topic
. Partition
. Producer
. Consumer
. Message
. Stream

==== Topic 

image::/images/kafka-notes/log-anatomy.png[]

==== Partition

当存在多副本的情况下，会尽量把多个副本，分配到不同的broker上。kafka会为partition选出一个leader，之后所有该partition的请求，实际操作的都是leader，然后再同步到其他的follower。

==== Producer

攒一批，然后再发送。

疑问来了：配置了 ack 数，没有及时发送，怎么确认是否发送成功？


Broker 收到针对特定分区的请求时，如果分区首领不在该 Broker 时，返回“非分区首领”的错误响应。难道需要客户端自己处理这种错误吗？客户端不会自动把请求发送到正确的 Broker 上吗？

==== Consumer

NOTE: 研究一下零拷贝技术以及在 Java 中的实现！


image::/images/kafka-notes/log-consumer.png[]

image::/images/kafka-notes/consumer-groups.png[]

==== Message

==== Stream

=== 重要更新

. New API
. Stream
. ..

== 架构

速度之谜

. 顺序读写
. 零拷贝
. 消息压缩
. 分批发送

image::/images/kafka-notes/kafka-architecture-2.webp[]

image::/images/kafka-notes/mq-p2p.webp[]

image::/images/kafka-notes/mq-publish-subscribe.webp[]

=== Replica 副本

image::/images/kafka-notes/data-flow.webp[]

=== Consumer Group 消费者组

=== 网络设计

=== 日志格式

image::/images/kafka-notes/kafka-log.png[]

image::/images/kafka-notes/log-cleaner-anatomy.png[]

image::/images/kafka-notes/log-compaction.png[]

Kafka的消息层次都是分为两层：消息集合(message set)以及消息(message)。一个消息集合中包含若干多条日志项，而每个日志项封装了消息以及其他一些元数据。Kafka底层的消息日志则由一系列消息集合日志项组成的。Kafka不会在消息这个层面上直接操作，它总是在消息集合这个层面上进行写入操作。

image::/images/kafka-notes/msg-format-v1.png[]

image::/images/kafka-notes/msg-batch-format-v1.png[]

老版本的消息集合在设计上有一些弊端：

. 对空间的利用率不高，比如不论key和value的长度是多少，老版本消息都是用固定的4个字节来保存长度信息。
. 老版本设计中的offset是消息集合的最后一条消息的offset，如果用户想要获取第一条消息的位移，必须要把所有消息解压全部装入内存然后反向遍历才能获取到。
. CRC的计算有些鸡肋。
. 每次需要单条消息的总长度信息时都需要计算而得出，没有使用一个字段来保存下来，解序列化效率不高。

image::/images/kafka-notes/msg-format-v2.png[]

image::/images/kafka-notes/msg-batch-format-v2.png[]


保存在磁盘上的数据格式与从生产者发送过来或者发送给消费者的消息格式是一样的。因为使用相同的消息格式进行存储或网络传输，Kafka 就可以使用零拷贝技术给消费者发送消息。

****
. 消息格式中， TimeOffset 和 分区 Offset 怎么设置啊？
. 消息集合大于消费者消费的上限又该怎么办？
****


=== ZooKeeper 上的元信息

=== 控制器

== 最佳实践

== 典型问题

. 新加节点的平衡问题
. 幂等性，Exactly Once

== 生态

image::/images/kafka-notes/chart-kafka-infrastructure@2x.png[]

查看 https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem[Ecosystem - Apache Kafka]。

. ZooKeeper
. Apache Spark
. Apache Storm
. Apache Flink
. Apache Hadoop
. Apache HBase
. Apache Cassandra
. ElasticSearch
. Kafka Connect
. Kafka KSQL
. Apache Log4j 2
. ELK

== 横向对比

https://www.infoq.com/articles/apache-kafka/[Apache Kafka: Next Generation Distributed Messaging System]



=== 与 Apache Pulsar 的对比

存储

. https://blog.csdn.net/pushme_pli/article/details/85918085[RabbitMQ, Kafka和Pulsar (一)_大数据_pushme_pli的专栏-CSDN博客]
. https://blog.csdn.net/pushme_pli/article/details/85984404[RabbitMQ, Kafka和Pulsar (二)_Java_pushme_pli的专栏-CSDN博客]
. https://blog.csdn.net/pushme_pli/article/details/86060761[RabbitMQ, Kafka和Pulsar (三)_大数据_pushme_pli的专栏-CSDN博客]
. https://blog.csdn.net/u010869257/article/details/83211152[理解Apache Pulsar工作原理_大数据_u010869257的博客-CSDN博客]
. https://jack-vanlightly.com/blog/2018/10/2/understanding-how-apache-pulsar-works[Understanding How Apache Pulsar Works — Jack Vanlightly]
. https://github.com/aCoder2013/blog/issues/23[下一代分布式消息队列Apache Pulsar从入门到实现(一) · Issue #23 · aCoder2013/blog]
. https://blog.csdn.net/liyiming2017/article/details/83748080[Pulsar官方文档翻译-概念和架构-架构概述（Architecture Overview）_大数据_稀有气体的技术博客-CSDN博客]
. https://blog.csdn.net/kaiyuanshe/article/details/102951317[Apache Pulsar：一个没有国界的社区_Python_kaiyuanshe的博客-CSDN博客]
. https://zhuanlan.zhihu.com/p/47388267[比拼Kafka，大数据分析新秀Pulsar到底好在哪 - 知乎] -- 写的很全面

=== 与 Apache RocketMQ 的对比

可靠性


=== 与 RabbitMQ 的对比

https://aws.amazon.com/cn/msk/what-is-kafka/[What is Apache Kafka? | AWS]

. 速度
. 扩展性

== 参考资料

. http://kafka.apache.org/[Apache Kafka]
. https://rocketmq.apache.org/[Apache RocketMQ]
. https://pulsar.apache.org/[Apache Pulsar]
. https://www.rabbitmq.com/[RabbitMQ]
. https://activemq.apache.org/[ActiveMQ]
. https://docs.confluent.io/current/connect/index.html[Kafka Connect — Confluent Platform]
. https://www.confluent.io/product/ksql/[KSQL: Streaming SQL for Apache Kafka | Confluent]
. https://spring.io/projects/spring-kafka[Spring for Apache Kafka]
. https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem[Ecosystem - Apache Kafka]
. https://aws.amazon.com/cn/blogs/big-data/best-practices-for-running-apache-kafka-on-aws/[Best Practices for Running Apache Kafka on AWS | AWS Big Data Blog]
. https://aws.amazon.com/cn/msk/what-is-kafka/[What is Apache Kafka? | AWS]
. https://www.confluent.io/what-is-apache-kafka/[What is Apache Kafka? | Confluent]
. https://www.infoq.com/articles/apache-kafka/[Apache Kafka: Next Generation Distributed Messaging System]
. https://dzone.com/articles/apache-kafka-is-the-new-black-at-the-edge-in-iot-p[Apache Kafka Is the New Black at the Edge in IoT Projects - DZone IoT]
. https://techbeacon.com/app-dev-testing/what-apache-kafka-why-it-so-popular-should-you-use-it[What is Apache Kafka? Why is it so popular? Should I use it?]
. https://sookocheff.com/post/kafka/kafka-in-a-nutshell/[Kafka in a Nutshell - Kevin Sookocheff]
. https://livebook.manning.com/book/activemq-in-action/chapter-1[ActiveMQ in Action]
. https://www.cnblogs.com/lbzhello/p/kafka-20190708.html[图解kafka - 设计原理解析 - lbzhello - 博客园]
. https://mp.weixin.qq.com/s/sFoo5HBLwBNS7WFAyOcTsA[真的，关于 Kafka 入门看这一篇就够了]
. https://www.cnblogs.com/huxi2b/p/7126410.html[【原创】Kafka 0.11消息设计 - huxihx - 博客园]
. https://mp.weixin.qq.com/s/9fJchPJa_raHSkvo29bkEA[如何快速全面掌握Kafka？5000字吐血整理]
. https://mp.weixin.qq.com/s/9B-iI_XiPkF20eN6jWuhzw[大数据中台之Kafka，到底好在哪里？]



== 处理流程

=== 存在的问题及设计目标


=== 生产

. 批量发送
. 同步/异步都支持 -- 通过 `Future` 支持
. 压缩
. 序列化
.. Schema Registry
. Partition 选择
.. 轮询
.. Partitioner
.. 直接指定
. 重试

=== 服务端

. NIO，Reactor 模式
.. 将 Acceptor、READ、WRITE 等等全部进行线程池化，防止单个请求拖慢全部请求。
. 顺序写
. 零拷贝
. 日志持久化
.. 格式变化
.. 稀疏阵列
.. 跳跃表
.. 选举
. 复制
. Topic、Partition 在 Broker 中的分布

=== 复本之间的复制

=== 消费

. 点对点、发布/订阅的统一
. Rebalance
. 消费offset
. 生产的时候需要分区Leader，消费的时候需要分区 Leader 吗？如果平衡多个消费？

=== 集群观念里

. 创建 Topic
. 可用版本号


== 随笔

=== 震惊了！原来这才是 Kafka！（多图+深入）

https://mp.weixin.qq.com/s?src=11&timestamp=1583393732&ver=2197&signature=qoN3LouT7wiFtX35WibTlVCeKQ7cT8AcF7QKRc4*293KcvpAxf1o-1QZvbJDQALvFe1UcJuiJNGweERni8eDy7VOmoCV57keEBhaTECyhJJNgtKp-ZnqerVMaAq5nL2d&new=1[震惊了！原来这才是 Kafka！（多图+深入）]

创建一条记录，记录中一个要指定对应的topic和value，key和partition可选。 先序列化，然后按照topic和partition，放进对应的发送队列中。kafka produce都是批量请求，会积攒一批，然后一起发送，不是调send()就进行立刻进行网络发包。

如果partition没填，那么情况会是这样的：

. key有填，按照key进行哈希，相同key去一个partition。（如果扩展了partition的数量那么就不能保证了）
. key没填,round-robin来选partition

这些要发往同一个partition的请求按照配置，攒一波，然后由一个单独的线程一次性发过去。


当存在多副本的情况下，会尽量把多个副本，分配到不同的broker上。kafka会为partition选出一个leader，之后所有该partition的请求，实际操作的都是leader，然后再同步到其他的follower。

关于partition的分配，还有leader的选举，总得有个执行者。在kafka中，这个执行者就叫controller。

partition的分配

. 将所有Broker（假设共n个Broker）和待分配的Partition排序
. 将第i个Partition分配到第（i mod n）个Broker上 （这个就是leader）
. 将第i个Partition的第j个Replica分配到第（(i + j) mode n）个Broker上

controller会在Zookeeper的/brokers/ids节点上注册Watch，一旦有broker宕机，它就能知道。当broker宕机后，controller就会给受到影响的partition选出新leader。controller从zk的/brokers/topics/[topic]/partitions/[partition]/state中，读取对应partition的ISR（in-sync replica已同步的副本）列表，选一个出来做leader。

选出leader后，更新zk，然后发送LeaderAndISRRequest给受影响的broker，让它们改变知道这事。

如果ISR列表是空，那么会根据配置，随便选一个replica做leader，或者干脆这个partition就是歇菜。如果ISR列表的有机器，但是也歇菜了，那么还可以等ISR的机器活过来。


多副本同步，服务端这边的处理是follower从leader批量拉取数据来同步。生产者生产消息的时候，通过request.required.acks参数来设置数据的可靠性。

****
选举leader后，数据如何同步？不一致的数据如何处理？

思考：

当acks=-1时

是follwers都来fetch就返回成功，还是等follwers第二轮fetch？

leader已经写入本地，但是ISR中有些机器失败，那么怎么处理呢？
****


订阅topic是以一个消费组来订阅的，一个消费组里面可以有多个消费者。同一个消费组中的两个消费者，不会同时消费一个partition。换句话来说，就是一个partition，只能被消费组里的一个消费者消费，但是可以同时被多个消费组消费。


订阅topic时，可以用正则表达式，如果有新topic匹配上，那能自动订阅上。


在0.10版本后，kafka把这个offset的保存，从zk总剥离，保存在一个名叫__consumeroffsets topic的topic中。写进消息的key由groupid、topic、partition组成，value是偏移量offset。topic配置的清理策略是compact。总是保留最新的key，其余删掉。一般情况下，每个key的offset都是缓存在内存中，查询的时候不用遍历partition，如果没有缓存，第一次就会遍历partition建立缓存，然后查询返回。


****
思考：
如果正在跑的服务，修改了offsets.topic.num.partitions，那么offset的保存是不是就乱套了？
****

****
reblance 是怎样的一个流程？
****

当partition或者消费者的数量发生变化时，都得进行reblance。列举一下会reblance的情况：

. 增加partition
. 增加消费者
. 消费者主动关闭
. 消费者宕机了
. coordinator自己也宕机了



Exactly once

思路是这样的，首先要保证消息不丢，再去保证不重复。首先想出来的：

. 生产者重做导致重复写入消息----生产保证幂等性
. 消费者重复消费---消灭重复消费，或者业务接口保证幂等性重复消费也没问题

由于业务接口是否幂等，不是kafka能保证的，所以kafka这里提供的exactly once是有限制的，消费者的下游也必须是kafka。

解决重复消费有两个方法：

. 下游系统保证幂等性，重复消费也不会导致多条记录。
. 把commit offset和业务处理绑定成一个事务。

把重复消费的问题从根源上解决，把commit offset和输出到其他topic绑定成一个事务。

****
Kafa 怎么实现事务的？Kafka 的事务和数据库的事务怎么实现统一？

在 Kafka 中如何实现幂等性？
****


kafka的数据，实际上是以文件的形式存储在文件系统的。topic下有partition，partition下有segment，segment是实际的一个个文件，topic和partition都是抽象概念。


每个segment文件大小相等，文件名以这个segment中最小的offset命名，文件扩展名是.log；segment对应的索引的文件名字一样，扩展名是.index。有两个index文件，一个是offset index用于按offset去查message，一个是time index用于按照时间去查。

为了减少索引文件的大小，降低空间使用，方便直接加载进内存中，这里的索引使用稀疏矩阵，不会每一个message都记录下具体位置，而是每隔一定的字节数，再建立一条索引。 索引包含两部分，分别是baseOffset，还有position。

baseOffset：意思是这条索引对应segment文件中的第几条message。这样做方便使用数值压缩算法来节省空间。例如kafka使用的是varint。

position：在segment中的绝对位置。

=== Kafka学习路径图：从入门、原理到实战 | 极客时间

购买专栏看看？

=== Kafka设计原理看了又忘，忘了又看？

. 削峰
. 解耦

image::/images/kafka-notes/kafka-architecture.webp[]

Message 是按照 Topic 来组织的，每个 Topic 可以分成多个 Partition（对应 server.properties/num.partitions）。

Kafka 的 Message 存储采用了分区（Partition），磁盘顺序读写，分段（LogSegment）和稀疏索引这几个手段来达到高效性。

==== Replica 同步

Kafka 通过"拉模式"同步消息，即 Follower 从 Leader 批量拉取数据来同步。


image::/images/kafka-notes/kafka-sdk-product-flow.webp[]


Offset 保存在名叫 __consumeroffsets 的 Topic 中。写消息的 Key 由 GroupId、Topic、Partition 组成，Value 是 Offset。